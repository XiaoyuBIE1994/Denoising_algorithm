{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IOGS : Reconnaissance des formes - TP Deep Learning\n",
    "# PARTIE 2 : Réseaux récurrents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les réseaux récurrents sont utilisés pour traiter des tâches répétitives, avec une dimension temporelle:\n",
    "* Prédiction de séquence (prédire le futur), c'est l'objet de ce TP\n",
    "* Traitement du texte (la séquence est ici le mot et/ou la phrase)\n",
    "* Traitement du son\n",
    "* ...\n",
    "\n",
    "Ces réseaux sont aujourd'hui de plus en plus utilisés, notamment grâce à quelques innovations récentes qui ont facilité la convergence et améliorer les performances (LSTM, GRU...).\n",
    "\n",
    "Dans ce TP nous utiliserons la version la plus simple des réseaux récurrent (SimpleRNN dans Keras).\n",
    "\n",
    "![RNN](rnn.jpg)\n",
    "\n",
    "Image from http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-1-introduction-to-rnns/.\n",
    "\n",
    "La sortie au temps t dépend de l'état s au temps t-1 :\n",
    "\\begin{equation*}\n",
    "o_t = f(Ux_t + W s_{t-1})\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "#from keras.datasets import cifar10, cifar100\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "# Build the CNN model\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conv layer 1 \n",
    "## input shape (32,32,1)\n",
    "## output shape (32,32,32)\n",
    "## Dilated Convolution + ReLU, dilation factor: 1\n",
    "model.add(Conv2D(\n",
    "        filters = 64,\n",
    "        kernel_size = (3,3),\n",
    "        padding = 'same',\n",
    "        dilation_rate = 1,\n",
    "        input_shape = [32,32,1]\n",
    "        ))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# Conv layer 2 \n",
    "## input shape (32,32,1)\n",
    "## output shape (32,32,32)\n",
    "## Dilated Convolution + Batch Normalization + ReLU, dilation factor: 2\n",
    "model.add(Conv2D(\n",
    "        filters = 64,\n",
    "        kernel_size = (3,3),\n",
    "        padding = 'same',\n",
    "        dilation_rate = 2\n",
    "        ))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "\n",
    "# Conv layer 3\n",
    "## input shape (32,32,1)\n",
    "## output shape (32,32,32)\n",
    "## Dilated Convolution + Batch Normalization + ReLU, dilation factor: 3\n",
    "model.add(Conv2D(\n",
    "        filters = 64,\n",
    "        kernel_size = (3,3),\n",
    "        padding = 'same',\n",
    "        dilation_rate = 3\n",
    "        ))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# Conv layer 4\n",
    "## input shape (32,32,1)\n",
    "## output shape (32,32,32)\n",
    "## Dilated Convolution + Batch Normalization + ReLU, dilation factor: 4\n",
    "model.add(Conv2D(\n",
    "        filters = 64,\n",
    "        kernel_size = (3,3),\n",
    "        padding = 'same',\n",
    "        dilation_rate = 4\n",
    "        ))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# Conv layer 5\n",
    "## input shape (32,32,1)\n",
    "## output shape (32,32,32)\n",
    "## Dilated Convolution + Batch Normalization + ReLU, dilation factor: 3\n",
    "model.add(Conv2D(\n",
    "        filters = 64,\n",
    "        kernel_size = (3,3),\n",
    "        padding = 'same',\n",
    "        dilation_rate = 3\n",
    "        ))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# Conv layer 6\n",
    "## input shape (32,32,1)\n",
    "## output shape (32,32,32)\n",
    "## Dilated Convolution + Batch Normalization + ReLU, dilation factor: 2\n",
    "model.add(Conv2D(\n",
    "        filters = 64,\n",
    "        kernel_size = (3,3),\n",
    "        padding = 'same',\n",
    "        dilation_rate = 2\n",
    "        ))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# Conv layer 7\n",
    "## input shape (32,32,1)\n",
    "## output shape (32,32,32)\n",
    "## Dilated Convolution dilation factor: 1\n",
    "model.add(Conv2D(\n",
    "        filters = 64,\n",
    "        kernel_size = (3,3),\n",
    "        padding = 'same',\n",
    "        dilation_rate = 1\n",
    "        ))\n",
    "# Define the optimizer\n",
    "adam= Adam(lr=1e-3)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss = 'mse', \n",
    "              optimizer = adam,\n",
    "              metrics = ['accuracy']                     \n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>QUESTION : normaliser les données entre 0 et 1 (des nombres pas trop grands permettent au réseau de converger plus rapidement)</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# scale the data\n",
    "data = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>QUESTION : couper les données en données d'entraînement (les 2 premiers tiers) et données de test (dernier tiers)</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split into train and test sets\n",
    "train_size = ...\n",
    "test_size = ...\n",
    "train, test = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons créer maintenant les séquences qui serviront pour entraîner notre réseau."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the datasets\n",
    "\n",
    "# convert an array of values into a dataset matrix\n",
    "def create_dataset(dataset, look_back=1):\n",
    "\tdataX, dataY = [], []\n",
    "\tfor i in range(len(dataset)-look_back-1):\n",
    "\t\ta = dataset[i:(i+look_back)]\n",
    "\t\tdataX.append(a)\n",
    "\t\tdataY.append(dataset[i + look_back])\n",
    "\treturn np.array(dataX), np.array(dataY)\n",
    "\n",
    "# reshape into X=t and Y=t+1\n",
    "look_back = 3\n",
    "trainX, trainY = create_dataset(train, look_back)\n",
    "testX, testY = create_dataset(test, look_back)\n",
    "# reshape input to be [samples, time steps, features]\n",
    "trainX = np.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
    "testX = np.reshape(testX, (testX.shape[0], 1, testX.shape[1]))\n",
    "print(trainX.shape)\n",
    "print(testX.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>QUESTION : Créer un réseau de neurones avec une couche de RNN à 4 neurones</b>\n",
    "<br/>\n",
    "On pourra s'inspirer de la première partie du TP. La couche est ```SimpleRNN(number_of_neurons, input_shape=(1, look_back))```\n",
    "<br/>\n",
    "<b>QUESTION : Créer l'optimiseur</b>\n",
    "<br/>\n",
    "<b>QUESTION : Compiler le modèle</b>\n",
    "<br/>\n",
    "La fonction de perte à utiliser est ```loss='mean_squared_error'```\n",
    "<br/>\n",
    "<b>QUESTION : Entraîner le modèle</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create and fit the RNN network\n",
    "batch_size = 10\n",
    "epochs = 30\n",
    "# create and fit the RNN network\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>QUESTION : prédire sur le dataset d'entraînement et le dataset de test</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make predictions\n",
    "trainPredict = ...\n",
    "testPredict = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>QUESTION : Afficher la courbe de référence, la courbe de prédiction sur les données d'entraînement et la courbe de prédiction sur les données de test.</b>\n",
    "<br/>\n",
    "On prendra soin d'afficher les données en fonction du temps (les données de test feront suite aux données de train)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testPredict = testPredict.ravel()\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>QUESTION : Conclure</b>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
